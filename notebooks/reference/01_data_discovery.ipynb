{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This notebook describes the typical activities carried out  at the beginning to a project / thread when customer shares new data. We will be trying to understand the tables, columns and information flow. Typically we also look for data issues and confirm with respective owners for resolution. At the end of this activity, the data sources and their treatment is finalized. Code in this notebook will not be part of the production code.\n",
    "\n",
    "This data can be downloaded from\n",
    "[here](https://drive.google.com/file/d/11DqcBxxEcn3QA4YvPQmmExBm-m6AgUQ_/view?usp=sharing)\n",
    "\n",
    "**NOTE**:\n",
    "Download the data from the above link, and copy the extracted csv files to the path `data/raw/sales/` (relative to root of the code archive folder). Make sure to copy the files before continuing on with the rest of the notebook.\n",
    "\n",
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Third-party imports\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "\n",
    "# Project imports\n",
    "from ta_lib.core.api import display_as_tabs, initialize_environment\n",
    "\n",
    "# Initialization\n",
    "initialize_environment(debug=False, hide_warnings=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Background\n",
    "\n",
    "Customer is a distributor of electronic devices. They partner with manufacturers, carriers and refurbishers and sell across to  retailers. The selling price is the outcome of negotiation between sales representatives and retailers. Customer wants to understand the selling price variation and determine  optimal pricing with Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ta_lib.core.api import create_context, list_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = op.join('conf', 'config.yml')\n",
    "context = create_context(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/raw/orders',\n",
       " '/raw/product',\n",
       " '/cleaned/orders',\n",
       " '/cleaned/product',\n",
       " '/cleaned/sales',\n",
       " '/processed/sales',\n",
       " '/train/sales/features',\n",
       " '/train/sales/target',\n",
       " '/test/sales/features',\n",
       " '/test/sales/target',\n",
       " '/score/sales/output']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_datasets(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m orders_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw/orders\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m prod_df \u001b[38;5;241m=\u001b[39m load_dataset(context, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw/product\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/housing-price-prediction/src/ta_lib/core/dataset.py:93\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(context, key, skip, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m fs \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mfs(context, ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m], ds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcredential_id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     92\u001b[0m data_uri \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mglob(ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 93\u001b[0m df \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mload_data(\u001b[43mdata_uri\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, fs\u001b[38;5;241m=\u001b[39mfs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mload_params)\n\u001b[1;32m     94\u001b[0m cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uri_ \u001b[38;5;129;01min\u001b[39;00m data_uri[\u001b[38;5;241m1\u001b[39m:]:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "orders_df = load_dataset(context, 'raw/orders')\n",
    "prod_df = load_dataset(context, 'raw/product')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "Given the raw data from data ingestion, we would now like to explore and learn more details about the data.\n",
    "\n",
    "\n",
    "The output of the step would be a summary report and discussion of any pertinent findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the eda API\n",
    "import ta_lib.eda.api as eda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_as_tabs([('orders', orders_df.shape), ('product', prod_df.shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1 = eda.get_variable_summary(orders_df)\n",
    "sum2 = eda.get_variable_summary(prod_df)\n",
    "\n",
    "display_as_tabs([('orders', sum1), ('product', sum2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "\n",
    "<details>\n",
    "1. Datatypes : We have both numeric and other types. The bulk of them seem to be numeric. `Numeric` is defined to be one of [float|int|date] and the rest are categorized as `Others`. A column is assumed to have `date` values if it has the string `date` in the column name.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging\n",
    "\n",
    "We can merge orders table with prod table on SKU. Let us check first-cut cardinality issues. \n",
    "\n",
    "### Expected data validation rules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Quantity should be an integer\n",
    "2. Quantity * UnitCost = SellingCost\n",
    "3. Quantity * UnitPrice = SellingPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_dict = {}\n",
    "orders_df = ge.from_pandas(orders_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule 1 verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_dict[\"rule_1_check\"] = orders_df.expect_column_values_to_be_of_type(\"Quantity\", \"int64\", mostly=None,\n",
    "                                             result_format=\"BASIC\", include_config=True).to_json_dict()\n",
    "\n",
    "if verification_dict[\"rule_1_check\"][\"success\"]:\n",
    "    print(\"Rule 1 passed\")\n",
    "else:\n",
    "    print(\"Rule 1 failed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule 2 verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df[\"selling_cal\"] = orders_df[\"Quantity\"] * orders_df[\"UnitCost\"]\n",
    "orders_df.selling_cal = orders_df.selling_cal.round()\n",
    "orders_df[\"act_selling_round\"] = orders_df.SellingCost.round()\n",
    "verification_dict[\"rule_2_check\"] = orders_df.expect_column_pair_values_to_be_equal(\"selling_cal\", \"act_selling_round\", mostly=None,\n",
    "                                             result_format=\"BASIC\", include_config=True).to_json_dict()\n",
    "\n",
    "if verification_dict[\"rule_2_check\"][\"success\"]:\n",
    "    print(\"Rule 2 passed\")\n",
    "else:\n",
    "    print(\"Rule 2 failed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule 3 verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df[\"selling_cal\"] = orders_df[\"Quantity\"] * orders_df[\"UnitPrice\"]\n",
    "orders_df.selling_cal = orders_df.selling_cal.round()\n",
    "orders_df[\"act_selling_round\"] = orders_df.SellingPrice.round()\n",
    "verification_dict[\"rule_3_check\"] = orders_df.expect_column_pair_values_to_be_equal(\"selling_cal\", \"act_selling_round\", mostly=None,\n",
    "                                             result_format=\"BASIC\", include_config=True).to_json_dict()\n",
    "\n",
    "if verification_dict[\"rule_3_check\"][\"success\"]:\n",
    "    print(\"Rule 3 passed\")\n",
    "else:\n",
    "    print(\"Rule 3 failed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule 2,3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally by logic cost * units should give the total cost, however there are some orders where this condition is not matching. We should confirm these condition from client.\n",
    "\n",
    "Similar goes for Price * units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to Pandas\n",
    "orders_df = orders_df.drop('selling_cal', axis=1)\n",
    "orders_df = orders_df.drop('act_selling_round', axis=1)\n",
    "orders_df = pd.DataFrame(orders_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  ta_lib.core.api import setanalyse\n",
    "\n",
    "setanalyse(orders_df.SKU.tolist(),prod_df.SKU.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents a venn diagram on two lists. Left list is `A` & right one is `B`. `A-B` implies that are five SKUs in orders_df missing in product master. We can find them using unsimplied version.\n",
    "\n",
    "Let us look at the set `A-B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missings_master_skus = setanalyse(orders_df.SKU.tolist(),prod_df.SKU.tolist(),simplify=False)['A-B']\n",
    "missings_master_skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(('Records affected due to missing keys are {0} accounting to {1}% of orders').format(\n",
    "    orders_df.SKU.isin(missings_master_skus).sum(),np.round(orders_df.SKU.isin(missings_master_skus).mean()*100,2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since missing keys are very less we can proceed with inner join**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "\n",
    "<details>\n",
    "1. Cardinality with mulitple keys: If you have more than one key use setanalyse_df. You can pass dataframes instead of lists and the key columns\n",
    "2. Excess master data (if `B-A` >0 in above example) will not be concern\n",
    "3. If the `A-B` is larger, please check with client for alternative data sources. In case of left join keep a stragey for imputing.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master uniqueness\n",
    "\n",
    "Product master is expected to have non duplicate primary keys. Let us verify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet\n",
    "df_freq = prod_df.SKU.value_counts().reset_index()\n",
    "df_freq.columns = ['SKU','Frequency']\n",
    "fil_ = df_freq.Frequency>1\n",
    "if fil_.sum() > 0:\n",
    "    print((\"Found {0} duplicates in master. Sample duplicates are:\").format(fil_.sum()))\n",
    "    print(df_freq[fil_].head())\n",
    "else:\n",
    "    print(\"No duplciates in primary key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping inconsistent records\n",
    "print((\"No. of rows before dropping duplicate SKUs: {0}\".format(prod_df.shape[0])))\n",
    "fil_ = (prod_df.SKU == 'UNLKD SONY XPERIA XZS BLUE 32G') & (prod_df.color.str.strip() == 'BLACK')\n",
    "prod_df = prod_df[~fil_]\n",
    "print((\"No. of rows after dropping duplicate SKUs: {0}\".format(prod_df.shape[0])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an overview of the overall health of the dataset. This is usually quick to compute and hopefully highlights some problems to focus on.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Plot\n",
    "\n",
    "Provides a high level summary of the dataset health.\n",
    "\n",
    "**Watch out for:**\n",
    "\n",
    "* too few numeric values\n",
    "* high % of missing values\n",
    "* high % of duplicate values\n",
    "* high % of duplicate columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1, plot1 = eda.get_data_health_summary(orders_df, return_plot=True)\n",
    "sum2, plot2 = eda.get_data_health_summary(prod_df, return_plot=True)\n",
    "\n",
    "display_as_tabs([('orders', plot1), ('product', plot2)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "\n",
    "<details>\n",
    "1. Datatypes : We have both numeric and other types. The bulk of them seem to be numeric. `Numeric` is defined to be one of [float|int|date] and the rest are categorized as `Others`. A column is assumed to have `date` values if it has the string `date` in the column name.\n",
    "\n",
    "2. The missing value plot seems to indicate missing values are not present but we do have them. \n",
    "\n",
    "3. We are looking for duplicate observations (rows in the data). The plot shows the % of rows that are an exact replica of another row (using `df.duplicated`)\n",
    "\n",
    "4. We are looking for duplicate features (columns in the data).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values summary\n",
    "\n",
    "This provides an overall view focussing on amount of missing values in the dataset.\n",
    "\n",
    "**Watch out for:**\n",
    "* A few columns have significant number of missing values \n",
    "* Most columns have significant number of missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1, plot1 = eda.get_missing_values_summary(orders_df, return_plot=True)\n",
    "sum2, plot2 = eda.get_missing_values_summary(prod_df, return_plot=True)\n",
    "\n",
    "display_as_tabs([('orders', plot1), ('product', plot2)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev notes:**\n",
    "\n",
    "<details>\n",
    "    \n",
    "    * By default, the following are considered missing/NA values : `[np.Nan, pd.NaT, 'NA', None]`\n",
    "    * additional values can be passed to tigerml (add_additional_na_values)\n",
    "    * these are applied to all columns.\n",
    "    \n",
    "    * some of the above information can be learnt from the data discovery step (see discussion below)\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1 = eda.get_duplicate_columns(orders_df)\n",
    "sum2 = eda.get_duplicate_columns(prod_df)\n",
    "\n",
    "display_as_tabs([('orders', sum1), ('product', sum2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1 = eda.get_outliers(orders_df)\n",
    "sum2 = eda.get_outliers(prod_df)\n",
    "\n",
    "display_as_tabs([('orders', sum1), ('product', sum2)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Analysis report\n",
    "\n",
    "Generate a report that has all the above data in a single html. This could be useful to submit to a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ta_lib.reports.api import summary_report\n",
    "\n",
    "summary_report(orders_df, 'reports/orders.html')\n",
    "summary_report(prod_df, 'reports/prod.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prod: https://drive.google.com/file/d/1TM-T5HzAYpT8_1ugM5L6Bnfxp8r3uMem/view?usp=sharing\n",
    "\n",
    "orders: https://drive.google.com/file/d/1uvehi90v1HFtScZrtWg3pW2zpi-DFQ1Y/view?usp=sharing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
